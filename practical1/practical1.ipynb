{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1\n",
    "\n",
    "> Tinghao(Vitus) Xie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load data from disk\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))\n",
    "\n",
    "# Split data\n",
    "N, D = X.shape\n",
    "N_train = int(0.8 * N)\n",
    "N_test = N - N_train\n",
    "\n",
    "X_train = X[:N_train]\n",
    "y_train = y[:N_train]\n",
    "X_test = X[N_train:]\n",
    "y_test = y[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding What We're Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handin 1**: Make a bar chart showing the distribution of $y$ values appearing in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(y_train == i).sum() for i in range(3, 10)]\n",
    "plt.bar(range(3, 10), data)\n",
    "plt.title('White Wine Quality Distribution')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('#Wines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handin 2**: Report the mean squared error, i.e., the average of the squared residuals, using this simplest of predictors on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is always 5.87790935075541\n",
      "Mean squared error on training set is 0.7767779702311379\n",
      "Mean squared error on test set is 0.8138507187613643\n"
     ]
    }
   ],
   "source": [
    "y_train_avg = y.mean() # Average, will be used as our prediction temporarily\n",
    "print(\"Prediction is always\", y_train_avg)\n",
    "print(\"Mean squared error on training set is\", ((y_train - y_train_avg) ** 2).sum() / y_train.shape[0])\n",
    "print(\"Mean squared error on test set is\", ((y_test - y_train_avg) ** 2).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model Using Least Squares\n",
    "\n",
    "First standardize the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original mean and variance\n",
    "X_train_mean = X_train.mean(axis=0)\n",
    "X_train_var = X_train.var(axis=0)\n",
    "\n",
    "# Standardize the features\n",
    "X_train_standard = (X_train - X_train_mean) / np.sqrt(X_train_var)\n",
    "X_test_standard = (X_test - X_train_mean) / np.sqrt(X_train_var)\n",
    "\n",
    "# Also standardize the outputs to [-1, 1] for removing the bias term\n",
    "y_train_standard = (y_train - 6) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to consider about the constant term in the linear model now. So The linear model's closed form solution would simply be:\n",
    "\n",
    "$$\n",
    "\\hat{\\textbf y}=\\textbf X \\textbf w=\\textbf X_{train}(\\textbf X_{train}^T\\textbf X_{train})^{-1}\\textbf X_{train}^T\\textbf y\\\\\n",
    "or\\ \\textbf w=(\\textbf X_{train}^T\\textbf X_{train})^{-1}\\textbf X_{train}^T \\textbf y\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "# The weight matrix (shape of [11, 1])\n",
    "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_train_standard.transpose(), X_train_standard)), X_train_standard.transpose()), y_train_standard)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handin 3**: Report the mean squared error using the linear model on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on training set is 0.578697621214545\n",
      "Mean squared error on test set is 0.5784207178333369\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "y_eval = np.matmul(X_train_standard, w)\n",
    "y_eval = y_eval * 3 + 6\n",
    "print(\"Mean squared error on training set is\", ((y_train - y_eval) ** 2).sum() / y_train.shape[0])\n",
    "\n",
    "# Evaluate on testing set\n",
    "y_eval = np.matmul(X_test_standard, w)\n",
    "y_eval = y_eval * 3 + 6\n",
    "print(\"Mean squared error on test set is\", ((y_test - y_eval) ** 2).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handin 4**: Report the learning curves plot. Also, explain whether you think the model is underﬁtting or not, and how much data you need before getting the optimal test error.\n",
    "\n",
    "**Answer**:\n",
    "- From the curves below, we can tell that about 80 training samples would approch the optimal test error.\n",
    "- And with about 300 samples the training loss and test loss would be basically the same.\n",
    "- The model is underfitting, since the bias is high (and more data won't help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 20\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "while num_samples <= 600:\n",
    "    # Only use the first `num_samples` data points\n",
    "    x_standard = X_train_standard[:num_samples]\n",
    "    y_standard = y_train_standard[:num_samples]\n",
    "    y = y_train[:num_samples]\n",
    "    \n",
    "    # Closed form solution to the linear model\n",
    "    w = np.matmul(np.matmul(np.linalg.inv(np.matmul(x_standard.transpose(), x_standard)), x_standard.transpose()), y_standard)\n",
    "\n",
    "    # Predict and get train loss\n",
    "    y_eval = np.matmul(x_standard, w)\n",
    "    y_eval = y_eval * 3 + 6\n",
    "    train_loss.append(((y - y_eval) ** 2).sum() / num_samples)\n",
    "    \n",
    "    # Predict and get test loss\n",
    "    y_eval = np.matmul(X_test_standard, w)\n",
    "    y_eval = y_eval * 3 + 6\n",
    "    test_loss.append(((y_test - y_eval) ** 2).sum() / y_test.shape[0])\n",
    "\n",
    "    num_samples += 20\n",
    "\n",
    "# Plot the learning curve\n",
    "x_range = [i for i in range(601)][20::20]\n",
    "plt.plot(x_range, train_loss, '-', label='Train Loss')\n",
    "plt.plot(x_range, test_loss, '-', label='Test Loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('#Samples')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Basis Expansion with Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3135\n",
      "Val set size: 783\n",
      "Test set size: 980\n"
     ]
    }
   ],
   "source": [
    "# Load data from disk\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))\n",
    "\n",
    "# Split data to train & test\n",
    "N, D = X.shape\n",
    "N_train = int(0.8 * N)\n",
    "N_test = N - N_train\n",
    "\n",
    "X_train = X[:N_train]\n",
    "y_train = y[:N_train]\n",
    "X_test = X[N_train:]\n",
    "y_test = y[N_train:]\n",
    "\n",
    "# Further split train set to train & val, for selecting hyper-parameters\n",
    "N_train = X_train.shape[0]\n",
    "N_val = int(N_train * .2)\n",
    "N_train = N_train - N_val\n",
    "\n",
    "X_val = X_train[N_train:]\n",
    "y_val = y_train[N_train:]\n",
    "X_train = X_train[:N_train]\n",
    "y_train = y_train[:N_train]\n",
    "\n",
    "print(\"Train set size: {}\\nVal set size: {}\\nTest set size: {}\".format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge] alpha = 10.0\n",
      "[Ridge] Mean squared error on train set is 0.4954631041385635\n",
      "[Ridge] Mean squared error on test set is 0.51166774565843\n",
      "[Lasso] alpha = 0.01\n",
      "[Lasso] Mean squared error on train set is 0.5138328252782884\n",
      "[Lasso] Mean squared error on test set is 0.5185523039167391\n"
     ]
    }
   ],
   "source": [
    "preprocess = make_pipeline(StandardScaler(), PolynomialFeatures(2))\n",
    "\n",
    "# Ridge\n",
    "alpha = 1e-2 # i.e. lambda\n",
    "val_loss = []\n",
    "for i in range(5):\n",
    "    clf = Ridge(alpha=alpha)\n",
    "    clf.fit(preprocess.fit_transform(X_train), y_train)\n",
    "    alpha *= 10\n",
    "    y_eval = clf.predict(preprocess.transform(X_val))\n",
    "    val_loss.append(((y_val - y_eval) ** 2).sum() / y_val.shape[0])\n",
    "# Choose the best alpha\n",
    "alpha = 1e-2 * (10 ** np.argmin(val_loss))\n",
    "print(\"[Ridge] alpha =\", alpha)\n",
    "# Train with full training set\n",
    "X_full_train = np.concatenate((X_train, X_val))\n",
    "y_full_train = np.concatenate((y_train, y_val))\n",
    "clf = Ridge(alpha=alpha)\n",
    "clf.fit(preprocess.fit_transform(X_full_train), y_full_train)\n",
    "# Evaluate\n",
    "y_eval = clf.predict(preprocess.transform(X_full_train))\n",
    "print(\"[Ridge] Mean squared error on train set is\", ((y_full_train - y_eval) ** 2).sum() / y_full_train.shape[0])\n",
    "y_eval = clf.predict(preprocess.transform(X_test))\n",
    "print(\"[Ridge] Mean squared error on test set is\", ((y_test - y_eval) ** 2).sum() / y_test.shape[0])\n",
    "\n",
    "# Lasso\n",
    "alpha = 1e-2 # i.e. lambda\n",
    "val_loss = []\n",
    "for i in range(5):\n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(preprocess.fit_transform(X_train), y_train)\n",
    "    alpha *= 10\n",
    "    y_eval = clf.predict(preprocess.transform(X_val))\n",
    "    val_loss.append(((y_val - y_eval) ** 2).sum() / y_val.shape[0])\n",
    "# Choose the best alpha\n",
    "alpha = 1e-2 * (10 ** np.argmin(val_loss))\n",
    "print(\"[Lasso] alpha =\", alpha)\n",
    "# Train with full training set\n",
    "X_full_train = np.concatenate((X_train, X_val))\n",
    "y_full_train = np.concatenate((y_train, y_val))\n",
    "clf = Lasso(alpha=alpha)\n",
    "clf.fit(preprocess.fit_transform(X_full_train), y_full_train)\n",
    "# Evaluate\n",
    "y_eval = clf.predict(preprocess.transform(X_full_train))\n",
    "print(\"[Lasso] Mean squared error on train set is\", ((y_full_train - y_eval) ** 2).sum() / y_full_train.shape[0])\n",
    "y_eval = clf.predict(preprocess.transform(X_test))\n",
    "print(\"[Lasso] Mean squared error on test set is\", ((y_test - y_eval) ** 2).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Degrees\n",
    "\n",
    "Use $k$-fold to determine hyperparameters using a higher degree basis expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3918\n",
      "Test set size: 980\n"
     ]
    }
   ],
   "source": [
    "# Load data from disk\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))\n",
    "\n",
    "# Split data to train & test\n",
    "N, D = X.shape\n",
    "N_train = int(0.8 * N)\n",
    "N_test = N - N_train\n",
    "\n",
    "X_full_train = X[:N_train]\n",
    "y_full_train = y[:N_train]\n",
    "X_test = X[N_train:]\n",
    "y_test = y[N_train:]\n",
    "\n",
    "print(\"Train set size: {}\\nTest set size: {}\".format(X_full_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with 5-fold\n",
    "\n",
    "The result seems somehow worse than 2-degree basis expansion (and without $k$-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 39.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 48.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 44.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge] Best alpha = 1000.0000000000001\n",
      "[Ridge] Previously, best mean squared error on val set is 0.5262248469891102\n",
      "[Ridge] Mean squared error on train set is 0.45629981715481616\n",
      "[Ridge] Mean squared error on test set is 0.5421485096673404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 3\n",
    "n_splits = 5\n",
    "alpha_init = 1e-5\n",
    "iter_alpha = 10\n",
    "factor = 10\n",
    "\n",
    "preprocess = make_pipeline(StandardScaler(), PolynomialFeatures(poly_degree))\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Ridge\n",
    "best_loss = np.Infinity\n",
    "best_alpha = alpha_init\n",
    "for train_index, test_index in kf.split(X_full_train):\n",
    "    X_train = X_full_train[train_index]\n",
    "    y_train = y_full_train[train_index]\n",
    "    X_val = X_full_train[test_index]\n",
    "    y_val = y_full_train[test_index]\n",
    "    \n",
    "    alpha = alpha_init # i.e. lambda\n",
    "    val_loss = []\n",
    "    for i in tqdm(range(iter_alpha)):\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(preprocess.fit_transform(X_train), y_train)\n",
    "        alpha *= factor\n",
    "        y_eval = clf.predict(preprocess.transform(X_val))\n",
    "        val_loss.append(((y_val - y_eval) ** 2).sum() / y_val.shape[0])\n",
    "    # Update globally best loss & alpha\n",
    "    if best_loss > np.min(val_loss):\n",
    "        best_loss = np.min(val_loss)\n",
    "        best_alpha = alpha_init * (factor ** np.argmin(val_loss))\n",
    "print(\"[Ridge] Best alpha =\", best_alpha)\n",
    "# Train with full training set\n",
    "clf = Ridge(alpha=best_alpha)\n",
    "clf.fit(preprocess.fit_transform(X_full_train), y_full_train)\n",
    "# Evaluate\n",
    "print(\"[Ridge] Previously, best mean squared error on val set is\", best_loss)\n",
    "y_eval = clf.predict(preprocess.transform(X_full_train))\n",
    "print(\"[Ridge] Mean squared error on train set is\", ((y_full_train - y_eval) ** 2).sum() / y_full_train.shape[0])\n",
    "y_eval = clf.predict(preprocess.transform(X_test))\n",
    "print(\"[Ridge] Mean squared error on test set is\", ((y_test - y_eval) ** 2).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with 5-fold\n",
    "\n",
    "The optimization seems difficult to converge for small $\\lambda$. But the best error (0.5072) seems a little better than 2-degree basis expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 583.1760394764294, tolerance: 0.24286818761965562\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 60%|██████    | 3/5 [00:04<00:02,  1.49s/it]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 306.33159506265724, tolerance: 0.24286818761965562\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.25s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 315.9951266439087, tolerance: 0.2481417038927884\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.81s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 605.1074466787804, tolerance: 0.24224904275686068\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 60%|██████    | 3/5 [00:04<00:02,  1.46s/it]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 235.84935635760053, tolerance: 0.24224904275686068\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.16s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 601.0264647763745, tolerance: 0.24151814992025525\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 60%|██████    | 3/5 [00:05<00:03,  1.85s/it]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.90388712193283, tolerance: 0.24151814992025525\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 80%|████████  | 4/5 [00:10<00:02,  2.91s/it]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.128369156126155, tolerance: 0.24151814992025525\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.15s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 614.9457729117424, tolerance: 0.24253282296650705\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 60%|██████    | 3/5 [00:05<00:03,  1.77s/it]/Users/vtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.9296020740014, tolerance: 0.24253282296650705\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lasso] Best alpha = 0.01\n",
      "[Lasso] Previously, best mean squared error on val set is 0.5095863010894448\n",
      "[Lasso] Mean squared error on train set is 0.46857682318417443\n",
      "[Lasso] Mean squared error on test set is 0.5071786105362784\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 3\n",
    "n_splits = 5\n",
    "alpha_init = 1e-4\n",
    "iter_alpha = 5\n",
    "factor = 10\n",
    "\n",
    "preprocess = make_pipeline(StandardScaler(), PolynomialFeatures(poly_degree))\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Lasso\n",
    "best_loss = np.Infinity\n",
    "best_alpha = alpha_init\n",
    "for train_index, test_index in kf.split(X_full_train):\n",
    "    X_train = X_full_train[train_index]\n",
    "    y_train = y_full_train[train_index]\n",
    "    X_val = X_full_train[test_index]\n",
    "    y_val = y_full_train[test_index]\n",
    "\n",
    "    alpha = alpha_init # i.e. lambda\n",
    "    val_loss = []\n",
    "    for i in tqdm(range(iter_alpha)):\n",
    "        if i < 2: continue\n",
    "        clf = Lasso(alpha=alpha, max_iter=5000)\n",
    "        clf.fit(preprocess.fit_transform(X_train), y_train)\n",
    "        alpha *= 10\n",
    "        y_eval = clf.predict(preprocess.transform(X_val))\n",
    "        val_loss.append(((y_val - y_eval) ** 2).sum() / y_val.shape[0])\n",
    "    # Update globally best loss & alpha\n",
    "    if best_loss > np.min(val_loss):\n",
    "        best_loss = np.min(val_loss)\n",
    "        best_alpha = alpha_init * (10 ** np.argmin(val_loss))\n",
    "print(\"[Lasso] Best alpha =\", best_alpha)\n",
    "# Train with full training set\n",
    "clf = Lasso(alpha=best_alpha, max_iter=5000)\n",
    "clf.fit(preprocess.fit_transform(X_full_train), y_full_train)\n",
    "# Evaluate\n",
    "print(\"[Lasso] Previously, best mean squared error on val set is\", best_loss)\n",
    "y_eval = clf.predict(preprocess.transform(X_full_train))\n",
    "print(\"[Lasso] Mean squared error on train set is\", ((y_full_train - y_eval) ** 2).sum() / y_full_train.shape[0])\n",
    "y_eval = clf.predict(preprocess.transform(X_test))\n",
    "print(\"[Lasso] Mean squared error on test set is\", ((y_test - y_eval) ** 2).sum() / y_test.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e53f07ebee17cdf3cdbf07b6e0bdd4ac384cbe92f6ed1708e1e90aab48f38486"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
